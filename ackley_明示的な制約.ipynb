{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import gpytorch\n",
    "import torch\n",
    "from gpytorch.constraints import Interval\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from torch import Tensor\n",
    "from torch.quasirandom import SobolEngine\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.double\n",
    "tkwargs = {\"device\": device, \"dtype\": dtype}\n",
    "\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")\n",
    "\n",
    "def get_initial_points(dim, n_pts, seed=0):\n",
    "    sobol = SobolEngine(dimension=dim, scramble=True, seed=seed)\n",
    "    X_init = sobol.draw(n=n_pts).to(dtype=dtype, device=device)\n",
    "    return X_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GenericDeterministicModel' object has no attribute 'squeeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstraint2\u001b[39m(X):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m X[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m# Example constraint: x2\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m cmodel1 \u001b[38;5;241m=\u001b[39m \u001b[43mGenericDeterministicModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     26\u001b[0m cmodel2 \u001b[38;5;241m=\u001b[39m GenericDeterministicModel(f\u001b[38;5;241m=\u001b[39mconstraint2)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     28\u001b[0m constraint_model \u001b[38;5;241m=\u001b[39m ModelList(cmodel1, cmodel2)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bo/lib/python3.11/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GenericDeterministicModel' object has no attribute 'squeeze'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from botorch.test_functions import Ackley\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.acquisition import UpperConfidenceBound\n",
    "from botorch.acquisition import qLogExpectedImprovement\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the Ackley function\n",
    "ackley = Ackley(dim=2,negate=True)\n",
    "\n",
    "from botorch.models import GenericDeterministicModel\n",
    "from botorch.models import ModelList\n",
    "from botorch.generation.sampling import ConstrainedMaxPosteriorSampling\n",
    "\n",
    "def constraint1(X):\n",
    "    return X[:, 0] - 1 # Example constraint: x1\n",
    "\n",
    "def constraint2(X):\n",
    "    return 2 - X[:, 1] # Example constraint: x2\n",
    "\n",
    "cmodel1 = GenericDeterministicModel(f=constraint1)\n",
    "cmodel2 = GenericDeterministicModel(f=constraint2)\n",
    "\n",
    "constraint_model = ModelList(cmodel1, cmodel2)\n",
    "\n",
    "\n",
    "# Generate initial training data\n",
    "train_x = torch.rand(100, 2) * 10 - 5  # 10 random points in [-5, 5]^2\n",
    "train_y = ackley(train_x).unsqueeze(-1)\n",
    "# Perform 10 trials\n",
    "for i in range(10):\n",
    "    # Fit a GP model\n",
    "    gp = SingleTaskGP(train_x, train_y)\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    fit_gpytorch_mll(mll)\n",
    "\n",
    "    # Define the acquisition function\n",
    "    best_f = train_y.max().item()\n",
    "    EI = qLogExpectedImprovement(model=gp, best_f=best_f)\n",
    "\n",
    "    # Optimize the acquisition function\n",
    "    bounds = torch.tensor([[-5.0, -5.0], [5.0, 5.0]], dtype=torch.float)\n",
    "\n",
    "    #CMPS = ConstrainedMaxPosteriorSampling(\n",
    "    #        gp, constraint_model\n",
    "    #    )\n",
    "    \n",
    "    constrained_thompson_sampling = ConstrainedMaxPosteriorSampling(\n",
    "        model=gp, constraint_model=constraint_model, replacement=False\n",
    "    )\n",
    "    print(\"train_x shape: \", train_x.shape)\n",
    "    candidate = constrained_thompson_sampling(train_x, num_samples=1)\n",
    "    #\n",
    "    #candidate, acq_value = optimize_acqf(\n",
    "    #    EI, bounds=bounds, q=1, num_restarts=5, raw_samples=20,\n",
    "    #)\n",
    "\n",
    "    # Evaluate the new candidate\n",
    "    new_y = ackley(candidate).unsqueeze(-1)\n",
    "\n",
    "    # Append the new data to the training set\n",
    "    train_x = torch.cat([train_x, candidate])\n",
    "    train_y = torch.cat([train_y, new_y])\n",
    "\n",
    "    print(f\"Trial {i+1}: Optimal point: {candidate}\")\n",
    "\n",
    "\n",
    "\n",
    "    #----------------------------------------    plot   ------------------------------------------------------\n",
    "    \n",
    "\n",
    "    # Create a grid of points\n",
    "    x = np.linspace(-5, 5, 100)\n",
    "    y = np.linspace(-5, 5, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = np.array([ackley(torch.tensor([x, y])).item() for x, y in zip(X.ravel(), Y.ravel())]).reshape(X.shape)\n",
    "\n",
    "    # Plot the contour\n",
    "    plt.contourf(X, Y, Z, levels=50, cmap='viridis')\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Scatter plot of training points and the candidate\n",
    "    plt.scatter(train_x[:, 0].numpy(), train_x[:, 1].numpy(), c='red', label='Training Points')\n",
    "    plt.scatter(candidate[:, 0].numpy(), candidate[:, 1].numpy(), c='blue', label='Candidate')\n",
    "    plt.legend()\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.title('Ackley Function Contour with Training Points and Candidate')\n",
    "    plt.show()\n",
    "\n",
    "    #----------------------------------------    plot   ------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models import GenericDeterministicModel\n",
    "from botorch.models import ModelList\n",
    "from botorch.generation.sampling import ConstrainedMaxPosteriorSampling\n",
    "\n",
    "def constraint1(X):\n",
    "    return X[:, 0] - 1 # Example constraint: x1\n",
    "\n",
    "def constraint2(X):\n",
    "    return 2 - X[:, 1] # Example constraint: x2\n",
    "\n",
    "cmodel1 = GenericDeterministicModel(f=constraint1)\n",
    "cmodel2 = GenericDeterministicModel(f=constraint2)\n",
    "\n",
    "constraint_model = ModelList(cmodel1, cmodel2)\n",
    "\n",
    "CMPS = ConstrainedMaxPosteriorSampling\n",
    "(\n",
    "            gp, constraint_model\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConstrainedMaxPosteriorSampling(\n",
       "  (model): SingleTaskGP(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (noise_prior): GammaPrior()\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (mean_module): ConstantMean()\n",
       "    (covar_module): ScaleKernel(\n",
       "      (base_kernel): MaternKernel(\n",
       "        (lengthscale_prior): GammaPrior()\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "      )\n",
       "      (outputscale_prior): GammaPrior()\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "  )\n",
       "  (objective): IdentityMCObjective()\n",
       "  (constraint_model): ModelList(\n",
       "    (models): ModuleList(\n",
       "      (0-1): 2 x GenericDeterministicModel()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 2 but got size 1 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# サンプリング実行\u001b[39;00m\n\u001b[1;32m     27\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# 入力サンプル\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[43mconstrained_thompson_sampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(samples)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bo/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bo/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bo/lib/python3.11/site-packages/botorch/generation/sampling.py:335\u001b[0m, in \u001b[0;36mConstrainedMaxPosteriorSampling.forward\u001b[0;34m(self, X, num_samples, observation_noise)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m, X: Tensor, num_samples: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, observation_noise: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    322\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    323\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sample from the model posterior.\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m            `X[..., i, :]` is the `i`-th sample.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 335\u001b[0m     posterior \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobservation_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobservation_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: `posterior_transform` is only used for the objective\u001b[39;49;00m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposterior_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m     Y_samples \u001b[38;5;241m=\u001b[39m posterior\u001b[38;5;241m.\u001b[39mrsample(sample_shape\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mSize([num_samples]))\n\u001b[1;32m    343\u001b[0m     c_posterior \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstraint_model\u001b[38;5;241m.\u001b[39mposterior(\n\u001b[1;32m    344\u001b[0m         X\u001b[38;5;241m=\u001b[39mX, observation_noise\u001b[38;5;241m=\u001b[39mobservation_noise\n\u001b[1;32m    345\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bo/lib/python3.11/site-packages/botorch/models/gpytorch.py:395\u001b[0m, in \u001b[0;36mBatchedMultiOutputGPyTorchModel.posterior\u001b[0;34m(self, X, output_indices, observation_noise, posterior_transform, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m     X, output_dim_idx \u001b[38;5;241m=\u001b[39m add_output_dim(\n\u001b[1;32m    390\u001b[0m         X\u001b[38;5;241m=\u001b[39mX, original_batch_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_batch_shape\n\u001b[1;32m    391\u001b[0m     )\n\u001b[1;32m    392\u001b[0m \u001b[38;5;66;03m# NOTE: BoTorch's GPyTorchModels also inherit from GPyTorch's ExactGP, thus\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# self(X) calls GPyTorch's ExactGP's __call__, which computes the posterior,\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# rather than e.g. SingleTaskGP's forward, which computes the prior.\u001b[39;00m\n\u001b[0;32m--> 395\u001b[0m mvn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observation_noise \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bo/lib/python3.11/site-packages/gpytorch/models/exact_gp.py:313\u001b[0m, in \u001b[0;36mExactGP.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m         train_input \u001b[38;5;241m=\u001b[39m train_input\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m*\u001b[39mbatch_shape, \u001b[38;5;241m*\u001b[39mtrain_input\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:])\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m*\u001b[39mbatch_shape, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:])\n\u001b[0;32m--> 313\u001b[0m     full_inputs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# Get the joint distribution for training/test data\u001b[39;00m\n\u001b[1;32m    316\u001b[0m full_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(ExactGP, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39mfull_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 2 but got size 1 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from botorch.models.deterministic import GenericDeterministicModel\n",
    "from botorch.generation.sampling import ConstrainedMaxPosteriorSampling\n",
    "from botorch.acquisition.objective import ConstrainedMCObjective\n",
    "\n",
    "# 制約関数を定義\n",
    "def constraint(x):\n",
    "    return torch.sum(x, dim=-1) - 1\n",
    "\n",
    "# 制約を満たすかどうかの判定関数\n",
    "def feasibility(x):\n",
    "    return constraint(x) <= 0\n",
    "\n",
    "# 制約付き目的関数を定義\n",
    "def constrained_objective(samples):\n",
    "    return samples[..., 0]  # 例として、最初の出力を最大化\n",
    "\n",
    "# GenericDeterministicModelを使用して制約モデルを作成\n",
    "f = lambda x: torch.ones_like(x[..., 0])\n",
    "constraint_model = GenericDeterministicModel(f=f)\n",
    "\n",
    "constrained_thompson_sampling = ConstrainedMaxPosteriorSampling(\n",
    "        model=constrained_objective, constraint_model=constraint_model, replacement=False\n",
    "    )\n",
    "\n",
    "# サンプリング実行\n",
    "X = torch.rand(10, 1)  # 入力サンプル\n",
    "samples = constrained_thompson_sampling(X)\n",
    "\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
